{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZcNZBOo_QWW"
      },
      "outputs": [],
      "source": [
        "# @title üé¨ **Video Interpolator (Supports 2x, 4x, 8x)**\n",
        "# @markdown Run this to interpolate video while **preserving original duration**.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import sys\n",
        "import glob\n",
        "from IPython.display import Video, display, clear_output\n",
        "\n",
        "# ================= CONFIGURATION =================\n",
        "INPUT_VIDEO = \"\"  # @param {type:\"string\"}\n",
        "# @markdown Leave blank to auto-detect the newest video.\n",
        "\n",
        "FRAME_MULTIPLIER = 2   # @param {type:\"number\"}\n",
        "# @markdown * **2** = 32fps (Standard Smooth)\n",
        "# @markdown * **4** = 64fps (Ultra Smooth)\n",
        "# @markdown * **8** = 128fps (Extreme)\n",
        "\n",
        "OUTPUT_NAME = \"interpolated_4x.mp4\" # @param {type:\"string\"}\n",
        "CRF_QUALITY = 17 # @param {type:\"slider\", min:0, max:51, step:1}\n",
        "\n",
        "# ================= SETUP =================\n",
        "print(\"üöÄ Initializing Environment...\")\n",
        "rife_dir = \"/content/Practical-RIFE\"\n",
        "\n",
        "if os.path.exists(rife_dir):\n",
        "    shutil.rmtree(rife_dir)\n",
        "os.makedirs(rife_dir, exist_ok=True)\n",
        "\n",
        "# 1. Download Model Files\n",
        "!wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/IFNet_HDv3.py -O {rife_dir}/IFNet_HDv3.py\n",
        "!wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/RIFE_HDv3.py -O {rife_dir}/RIFE_HDv3.py\n",
        "!wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/refine.py -O {rife_dir}/refine.py\n",
        "!wget -q https://huggingface.co/Isi99999/Frame_Interpolation_Models/resolve/main/4.25/train_log/flownet.pkl -O {rife_dir}/flownet.pkl\n",
        "\n",
        "# 2. Dependencies\n",
        "!pip install -q git+https://github.com/rk-exxec/scikit-video.git@numpy_deprecation\n",
        "!apt -y install -qq aria2 ffmpeg > /dev/null\n",
        "\n",
        "# ================= SHIMS & PATCHES =================\n",
        "print(\"üîß Applying Multi-Frame Logic...\")\n",
        "\n",
        "with open(f\"{rife_dir}/loss.py\", \"w\") as f:\n",
        "    f.write(\"import torch.nn as nn\\nclass EPE(nn.Module):\\n def __init__(self, a=None): super(EPE, self).__init__()\\n def forward(self, f, g): return 0\\nclass Sobel(nn.Module):\\n def __init__(self): super(Sobel, self).__init__()\\n def forward(self, i, g): return 0\\nclass SOBEL(Sobel): pass\")\n",
        "\n",
        "with open(f\"{rife_dir}/warplayer.py\", \"w\") as f:\n",
        "    f.write(\"import torch\\nimport torch.nn.functional as F\\ndevice=torch.device('cuda')\\ndef warp(tenInput, tenFlow):\\n backwarp_tenGrid = {}\\n if str(tenFlow.shape) not in backwarp_tenGrid:\\n  tenHorizontal = torch.linspace(-1.0, 1.0, tenFlow.shape[3]).view(1, 1, 1, tenFlow.shape[3]).expand(tenFlow.shape[0], -1, tenFlow.shape[2], -1)\\n  tenVertical = torch.linspace(-1.0, 1.0, tenFlow.shape[2]).view(1, 1, tenFlow.shape[2], 1).expand(tenFlow.shape[0], -1, -1, tenFlow.shape[3])\\n  backwarp_tenGrid[str(tenFlow.shape)] = torch.cat([tenHorizontal, tenVertical], 1).to(device)\\n tenFlow = torch.cat([tenFlow[:, 0:1, :, :] / ((tenInput.shape[3] - 1.0) / 2.0), tenFlow[:, 1:2, :, :] / ((tenInput.shape[2] - 1.0) / 2.0)], 1)\\n g = (backwarp_tenGrid[str(tenFlow.shape)] + tenFlow).permute(0, 2, 3, 1)\\n return torch.nn.functional.grid_sample(input=tenInput, grid=g, mode='bilinear', padding_mode='border', align_corners=True)\")\n",
        "\n",
        "def patch_file(filename, old, new):\n",
        "    path = f\"{rife_dir}/{filename}\"\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'r') as f: c = f.read()\n",
        "        if old in c:\n",
        "            with open(path, 'w') as f: f.write(c.replace(old, new))\n",
        "\n",
        "patch_file(\"RIFE_HDv3.py\", \"from train_log.IFNet_HDv3\", \"from IFNet_HDv3\")\n",
        "patch_file(\"RIFE_HDv3.py\", \"from model.loss\", \"from loss\")\n",
        "patch_file(\"RIFE_HDv3.py\", \"from model.warplayer\", \"from warplayer\")\n",
        "patch_file(\"IFNet_HDv3.py\", \"from model.warplayer\", \"from warplayer\")\n",
        "patch_file(\"IFNet_HDv3.py\", \"from model.loss\", \"from loss\")\n",
        "\n",
        "# ================= RECURSIVE INFERENCE SCRIPT =================\n",
        "# This logic supports 4x, 8x, etc. by recursively filling gaps\n",
        "inference_script = \"\"\"\n",
        "import sys\n",
        "sys.path.append('.')\n",
        "import cv2\n",
        "import torch\n",
        "import argparse\n",
        "import numpy as np\n",
        "import warnings\n",
        "import time\n",
        "from torch.nn import functional as F\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def make_inference(model, I0, I1, n):\n",
        "    # This recursive function handles 4x, 8x interpolation\n",
        "    if n == 1:\n",
        "        return []\n",
        "\n",
        "    # Generate middle frame (0.5)\n",
        "    if model.version >= 3.9:\n",
        "        mid = model.inference(I0, I1, 0.5, 1.0)\n",
        "    else:\n",
        "        mid = model.inference(I0, I1)\n",
        "\n",
        "    # Recursively fill left gap (0 to 0.5) and right gap (0.5 to 1.0)\n",
        "    return make_inference(model, I0, mid, n//2) + [mid] + make_inference(model, mid, I1, n//2)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--video', type=str, required=True)\n",
        "    parser.add_argument('--output', type=str, required=True)\n",
        "    parser.add_argument('--multi', type=int, default=2)\n",
        "    parser.add_argument('--scale', type=float, default=1.0)\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Load Model\n",
        "    try:\n",
        "        from RIFE_HDv3 import Model\n",
        "        model = Model()\n",
        "        model.load_model('.', -1)\n",
        "        model.eval()\n",
        "        model.device()\n",
        "        print(f\"‚úÖ RIFE Model Loaded\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Input Setup\n",
        "    cap = cv2.VideoCapture(args.video)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    tot = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "\n",
        "    if fps == 0: fps = 24.0\n",
        "\n",
        "    # 64-Pixel Padding\n",
        "    s_h, s_w = int(h * args.scale), int(w * args.scale)\n",
        "    ph = ((s_h - 1) // 64 + 1) * 64\n",
        "    pw = ((s_w - 1) // 64 + 1) * 64\n",
        "    padding = (0, pw - s_w, 0, ph - s_h)\n",
        "\n",
        "    # Calculate Target FPS (Maintains original duration)\n",
        "    target_fps = fps * args.multi\n",
        "\n",
        "    print(f\"‚ú® Input: {w}x{h} @ {fps} FPS\")\n",
        "    print(f\"‚ú® Output: {args.multi}x Frames @ {target_fps} FPS (Duration Locked)\")\n",
        "\n",
        "    writer = cv2.VideoWriter(args.output, cv2.VideoWriter_fourcc(*'mp4v'), target_fps, (s_w, s_h))\n",
        "\n",
        "    last = None\n",
        "    cnt = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: break\n",
        "\n",
        "            frame = cv2.resize(frame, (s_w, s_h))\n",
        "            I1 = torch.from_numpy(np.transpose(frame, (2,0,1))).to(device, non_blocking=True).unsqueeze(0).float() / 255.\n",
        "            I1 = F.pad(I1, padding)\n",
        "\n",
        "            if last is not None:\n",
        "                # RECURSIVE CALL for 4x support\n",
        "                mid_frames = make_inference(model, last, I1, args.multi)\n",
        "\n",
        "                # Write intermediate frames\n",
        "                for mid in mid_frames:\n",
        "                    mid = mid[0].cpu().numpy()\n",
        "                    mid = np.transpose(mid, (1, 2, 0))\n",
        "                    mid = (mid * 255).astype(np.uint8)\n",
        "                    mid = mid[:s_h, :s_w] # Crop\n",
        "                    writer.write(mid)\n",
        "\n",
        "            # Write Real Frame\n",
        "            writer.write(frame)\n",
        "            last = I1\n",
        "            cnt += 1\n",
        "            if cnt % 5 == 0:\n",
        "                print(f\"   Frame {cnt}/{tot}...\", end='\\\\r')\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    print(f\"\\\\n‚úÖ Processed {cnt} input frames in {time.time() - start_time:.2f}s\")\n",
        "\"\"\"\n",
        "with open(f\"{rife_dir}/inference_video.py\", \"w\") as f:\n",
        "    f.write(inference_script)\n",
        "\n",
        "# ================= EXECUTION =================\n",
        "if not INPUT_VIDEO:\n",
        "    mp4s = sorted(glob.glob(\"/content/*.mp4\") + glob.glob(\"/content/ComfyUI/output/*.mp4\"), key=os.path.getctime)\n",
        "    mp4s = [f for f in mp4s if \"interp\" not in f and \"final\" not in f]\n",
        "    INPUT_VIDEO = mp4s[-1] if mp4s else None\n",
        "\n",
        "if not INPUT_VIDEO:\n",
        "    print(\"‚ùå No input video found.\")\n",
        "    sys.exit()\n",
        "\n",
        "print(f\"üé¨ Source: {INPUT_VIDEO}\")\n",
        "temp_out = f\"{rife_dir}/temp_out.mp4\"\n",
        "final_out = f\"/content/{OUTPUT_NAME}\"\n",
        "\n",
        "os.environ[\"XDG_RUNTIME_DIR\"] = \"/tmp\"\n",
        "os.environ[\"SDL_AUDIODRIVER\"] = \"dummy\"\n",
        "\n",
        "%cd {rife_dir}\n",
        "!python3 inference_video.py --multi={FRAME_MULTIPLIER} --video=\"{INPUT_VIDEO}\" --scale=1.0 --output=\"{temp_out}\"\n",
        "%cd /content\n",
        "\n",
        "if os.path.exists(temp_out):\n",
        "    print(\"‚öôÔ∏è Finalizing (H.264)...\")\n",
        "    !ffmpeg -i \"{temp_out}\" -c:v libx264 -crf {CRF_QUALITY} -preset fast -y \"{final_out}\" -loglevel error\n",
        "    print(f\"üíæ Saved: {final_out}\")\n",
        "    display(Video(final_out, embed=True))\n",
        "else:\n",
        "    print(\"‚ùå Failed.\")"
      ]
    }
  ]
}